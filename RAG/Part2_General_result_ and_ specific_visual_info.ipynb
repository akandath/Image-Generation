{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 1)) (4.46.2)\n",
      "Requirement already satisfied: pinecone-client in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 2)) (5.0.1)\n",
      "Requirement already satisfied: pypdf in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 3)) (5.1.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 4)) (1.9.0)\n",
      "Requirement already satisfied: langchain in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 5)) (0.3.7)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 6)) (0.2.8)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 7)) (0.3.7)\n",
      "Requirement already satisfied: torch in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 8)) (2.5.1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 9)) (3.3.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 10)) (1.5.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 11)) (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 12)) (1.26.4)\n",
      "Requirement already satisfied: nltk in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 13)) (3.9.1)\n",
      "Requirement already satisfied: openai in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 14)) (1.54.4)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 15)) (1.0.1)\n",
      "Requirement already satisfied: llama-index in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 16)) (0.11.23)\n",
      "Requirement already satisfied: pymupdf in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 17)) (1.24.13)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 18)) (0.26.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 19)) (3.1.0)\n",
      "Requirement already satisfied: IProgress in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from -r requirements.txt (line 20)) (0.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from transformers->-r requirements.txt (line 1)) (3.16.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from transformers->-r requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from transformers->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from transformers->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from transformers->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from transformers->-r requirements.txt (line 1)) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from transformers->-r requirements.txt (line 1)) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from transformers->-r requirements.txt (line 1)) (4.67.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from pinecone-client->-r requirements.txt (line 2)) (2024.8.30)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from pinecone-client->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from pinecone-client->-r requirements.txt (line 2)) (0.0.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from pinecone-client->-r requirements.txt (line 2)) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from pinecone-client->-r requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain->-r requirements.txt (line 5)) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain->-r requirements.txt (line 5)) (3.11.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain->-r requirements.txt (line 5)) (0.3.18)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain->-r requirements.txt (line 5)) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain->-r requirements.txt (line 5)) (0.1.143)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain->-r requirements.txt (line 5)) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain->-r requirements.txt (line 5)) (8.5.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain-openai->-r requirements.txt (line 6)) (0.8.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 7)) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 7)) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 7)) (2.6.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch->-r requirements.txt (line 8)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch->-r requirements.txt (line 8)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch->-r requirements.txt (line 8)) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch->-r requirements.txt (line 8)) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch->-r requirements.txt (line 8)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 9)) (1.14.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 9)) (11.0.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 10)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 10)) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas->-r requirements.txt (line 11)) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas->-r requirements.txt (line 11)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas->-r requirements.txt (line 11)) (2024.2)\n",
      "Requirement already satisfied: click in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from nltk->-r requirements.txt (line 13)) (8.1.7)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from openai->-r requirements.txt (line 14)) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from openai->-r requirements.txt (line 14)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from openai->-r requirements.txt (line 14)) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from openai->-r requirements.txt (line 14)) (0.7.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from openai->-r requirements.txt (line 14)) (1.3.1)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.4 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index->-r requirements.txt (line 16)) (0.3.4)\n",
      "Requirement already satisfied: llama-index-cli<0.4.0,>=0.3.1 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index->-r requirements.txt (line 16)) (0.3.1)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.23 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index->-r requirements.txt (line 16)) (0.11.23)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.4 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index->-r requirements.txt (line 16)) (0.2.5)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index->-r requirements.txt (line 16)) (0.4.2)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index->-r requirements.txt (line 16)) (0.9.48.post4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.10 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index->-r requirements.txt (line 16)) (0.2.16)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index->-r requirements.txt (line 16)) (0.2.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index->-r requirements.txt (line 16)) (0.2.0)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index->-r requirements.txt (line 16)) (0.2.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.4.0,>=0.3.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index->-r requirements.txt (line 16)) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.3.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index->-r requirements.txt (line 16)) (0.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from datasets->-r requirements.txt (line 19)) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from datasets->-r requirements.txt (line 19)) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from datasets->-r requirements.txt (line 19)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from datasets->-r requirements.txt (line 19)) (0.70.16)\n",
      "Requirement already satisfied: six in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from IProgress->-r requirements.txt (line 20)) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 5)) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 5)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 5)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 5)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 5)) (1.17.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 14)) (3.10)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 7)) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 7)) (0.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 14)) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 14)) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain->-r requirements.txt (line 5)) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r requirements.txt (line 5)) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index->-r requirements.txt (line 16)) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index->-r requirements.txt (line 16)) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index->-r requirements.txt (line 16)) (1.2.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index->-r requirements.txt (line 16)) (1.6.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index->-r requirements.txt (line 16)) (1.16.0)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index->-r requirements.txt (line 16)) (0.1.5)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index-readers-file<0.4.0,>=0.3.0->llama-index->-r requirements.txt (line 16)) (4.12.3)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index-readers-file<0.4.0,>=0.3.0->llama-index->-r requirements.txt (line 16)) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index-readers-llama-parse>=0.3.0->llama-index->-r requirements.txt (line 16)) (0.5.14)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 5)) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 5)) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from tqdm>=4.27->transformers->-r requirements.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from jinja2->torch->-r requirements.txt (line 8)) (3.0.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.4.0,>=0.3.0->llama-index->-r requirements.txt (line 16)) (2.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain->-r requirements.txt (line 5)) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 7)) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipykernel in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (6.29.5)\n",
      "Requirement already satisfied: langchain_experimental in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (0.3.3)\n",
      "Requirement already satisfied: llama-index-vector-stores-pinecone in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: PyMuPDF in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (1.24.13)\n",
      "Requirement already satisfied: pinecone-client in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (5.0.1)\n",
      "Requirement already satisfied: pypdf in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: transformers in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (4.46.2)\n",
      "Requirement already satisfied: sentence_transformers in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipykernel) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipykernel) (8.29.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipykernel) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipykernel) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipykernel) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipykernel) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain_experimental) (0.3.18)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.10 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index-vector-stores-pinecone) (0.11.23)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from pinecone-client) (2024.8.30)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from pinecone-client) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from pinecone-client) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from pinecone-client) (2.2.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain_community) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain_community) (3.11.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.7 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain_community) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain_community) (0.1.143)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain_community) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from sentence_transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from sentence_transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from sentence_transformers) (1.14.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from sentence_transformers) (11.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.17.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (305.1)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain<0.4.0,>=0.3.7->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain<0.4.0,>=0.3.7->langchain_community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_experimental) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index-vector-stores-pinecone) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index-vector-stores-pinecone) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index-vector-stores-pinecone) (1.2.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index-vector-stores-pinecone) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index-vector-stores-pinecone) (3.9.1)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index-vector-stores-pinecone) (0.8.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index-vector-stores-pinecone) (1.16.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from SQLAlchemy<2.0.36,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_experimental) (3.0.0)\n",
      "Requirement already satisfied: click in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.10->llama-index-vector-stores-pinecone) (8.1.7)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain_community) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\hokla\\anaconda3\\envs\\myenv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hokla\\anaconda3\\envs\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hokla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install -r requirements.txt\n",
    "%pip install ipykernel langchain_experimental llama-index-vector-stores-pinecone ipykernel PyMuPDF pinecone-client pypdf faiss-cpu langchain_community transformers sentence_transformers\n",
    "\n",
    "import fitz\n",
    "\n",
    "import os, io, json, transformers, pinecone, pypdf, faiss, sqlite3, langchain_community, langchain, openai, math, time, nltk, torch, huggingface_hub, datasets\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "from dotenv import load_dotenv\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain import document_loaders, embeddings\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec, Pinecone         # vector store\n",
    "\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    SimpleDirectoryReader\n",
    ")\n",
    "\n",
    "from llama_index.core.extractors import (\n",
    "    QuestionsAnsweredExtractor,\n",
    "    TitleExtractor,\n",
    ")\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import util\n",
    "\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "openai = os.getenv('OPENAI_API_KEY')\n",
    "pinecone_api_key =os.getenv('PINECONE_API_KEY')\n",
    "environment =os.getenv('PINECONE_ENV')\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, io, re, requests, fitz\n",
    "import requests\n",
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    SimpleDirectoryReader\n",
    ")\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core.extractors import (\n",
    "    QuestionsAnsweredExtractor,\n",
    "    KeywordExtractor,\n",
    "    SummaryExtractor,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "openai = os.getenv('OPENAI_API_KEY')\n",
    "pinecone_api_key =os.getenv('PINECONE_API_KEY')\n",
    "environment =os.getenv('PINECONE_ENV')\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(r\"C:\\GenAIhw3\\product_info_pdf.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "text_parser = SentenceSplitter(\n",
    "    chunk_size=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\hokla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = []\n",
    "doc_idxs = []\n",
    "\n",
    "\n",
    "for doc_idx, page in enumerate(doc):\n",
    "    page_text = page.get_text(\"text\")\n",
    "    cur_text_chunks = text_parser.split_text(page_text)\n",
    "    text_chunks.extend(cur_text_chunks)\n",
    "    doc_idxs.extend([doc_idx] * len(cur_text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "\n",
    "for idx, text_chunk in enumerate(text_chunks):\n",
    "    node = TextNode(\n",
    "        text=text_chunk,\n",
    "    )\n",
    "    src_doc_idx = doc_idxs[idx]\n",
    "    src_page = doc[src_doc_idx]\n",
    "    nodes.append(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create the vector store using chosen similarity metrics:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_serverless = os.environ.get(\"USE_SERVERLESS\", \"False\").lower() == \"true\"\n",
    "\n",
    "if use_serverless:\n",
    "    spec = pinecone.ServerlessSpec(cloud='aws', region='us-east-1')\n",
    "else:\n",
    "    spec = pinecone.PodSpec(environment=environment)\n",
    "\n",
    "index_name = \"hw03\"\n",
    "\n",
    "if index_name in pc.list_indexes().names():\n",
    "    pc.delete_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = 1536          \n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name, \n",
    "    dimension=dimensions, \n",
    "    metric=\"cosine\",          \n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    )\n",
    ")\n",
    "\n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **choose a similarity metric to use for the vector store:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hw02\n",
      "hw03\n"
     ]
    }
   ],
   "source": [
    "for index in pc.list_indexes():\n",
    "    print(index['name'])\n",
    "\n",
    "pc.describe_index(\"hw03\")\n",
    "\n",
    "pc_index = pc.Index(index_name) \n",
    "\n",
    "vector_store = PineconeVectorStore(pinecone_index=pc_index)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pc_index.describe_index_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 1/37 [00:02<01:13,  2.05s/it]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.6452294206956307 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}.\n",
      "100%|| 37/37 [00:08<00:00,  4.28it/s]\n",
      "100%|| 37/37 [00:09<00:00,  4.00it/s]\n",
      "100%|| 37/37 [00:09<00:00,  3.82it/s]\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "extractors = [\n",
    "    KeywordExtractor(keywords=5, llm=llm),  \n",
    "    QuestionsAnsweredExtractor(questions=3, llm=llm), \n",
    "    SummaryExtractor(llm=llm),\n",
    "]\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=extractors,\n",
    ")\n",
    "nodes = await pipeline.arun(nodes=nodes, in_place=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***choose an embedding model to use for the vector store:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **OpenAI Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ada=\"text-embedding-ada-002\"\n",
    "small_txt_embedmodel_=\"text-embedding-3-small\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\", openai_api_key=openai)\n",
    "\n",
    "for node in nodes:\n",
    "    actual_text = node.get_content(metadata_mode=\"all\") \n",
    "    \n",
    "    node_embedding = embed_model.get_text_embedding(actual_text)\n",
    "    \n",
    "    node.embedding = node_embedding\n",
    "    \n",
    "    node.metadata[\"text_content\"] = actual_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **load the embeddings into the vector store (e.g. create a vector store):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserted vectors: 100%|| 37/37 [00:00<00:00, 56.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['7cda20c2-729a-4de4-9e49-b840a41b0eff',\n",
       " '731f9c30-c832-46f3-8f1b-cf56ed3826d4',\n",
       " 'ec06adcd-0ceb-4578-b666-2b3aa7c10a4e',\n",
       " 'c8563d7a-fc8c-45c2-8063-01c7f5d76f41',\n",
       " '987d3dd2-226d-4350-9f47-92b3a6958fb9',\n",
       " '272c7c6f-39b5-4f34-9281-b6cfd4076baf',\n",
       " '1c232e93-9bd1-49b0-a718-c2e07d3d47e0',\n",
       " 'cb8f2ac7-f5af-4912-9dbe-d7d33aee521d',\n",
       " '79a6b4d1-48a9-42cc-8e68-0e1cf18c8ebb',\n",
       " '648bcc9e-b63b-483b-8918-61ba23bdcb6e',\n",
       " '78a85337-66cd-4c94-a9ec-b0ceb0df7142',\n",
       " '89301c0f-0824-4674-9016-60e2902d8a43',\n",
       " '09f98389-0892-4642-aa7e-c2346e0475d0',\n",
       " 'bd345d6f-44ad-4347-8ec1-2f0ae1529ace',\n",
       " 'c57d3601-e485-470e-9a5f-bea48a8754dd',\n",
       " '8a8f5373-9e30-457c-a337-204dc9aa793b',\n",
       " '9845de5f-b1e5-4df2-baf1-2fe6efcf0e16',\n",
       " '8fbb6666-c0e2-4bd9-8238-2578bee707f4',\n",
       " '3abcffdc-f1be-4e60-bc62-6461504c17c4',\n",
       " '7bdbd7f5-e4e5-4afc-84a9-772e7a1c6e77',\n",
       " '679b552b-2ccf-48f5-a147-9f6704103cb5',\n",
       " '5df5bf44-ee43-4db0-ae3f-821ec41d42c5',\n",
       " '9a8359c2-c0cd-47e2-b6d5-b0dbe37df69c',\n",
       " '315c5565-818b-4dd8-b69c-7c546e84919c',\n",
       " '5a9e7041-eb01-4acb-8839-a16fef35e4ca',\n",
       " '81ce0b47-143d-4d03-8d1e-4c2d31239df7',\n",
       " '3763f81d-5dc0-4390-aae0-9ce8f30f0cae',\n",
       " '89a59d2f-7a86-49ce-9907-f2437362d855',\n",
       " 'f3f3d911-fa43-4d63-be0b-58c1be70eb16',\n",
       " '35b45686-18e4-4610-b8e5-2cb1a2608762',\n",
       " '8e0fcd59-e16a-4b1b-a28a-107c3353e1f0',\n",
       " '55c15473-34a1-428e-b9fd-407c9f850173',\n",
       " '53cd3bfd-82ed-48be-840f-99bd26884822',\n",
       " 'bacf0e6f-86da-455e-ac5d-207efbdad98a',\n",
       " '6a446046-13f3-4160-8f6e-f29ed862af39',\n",
       " '6b6f2a9c-c9da-4821-9a33-42b740ecef2e',\n",
       " '8dd8efaa-894b-4695-84f0-4c26416c58e7']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'excerpt_keywords': 'Breville, Espresso Machine, Specialty Coffee, Grinder, Latte Art', 'questions_this_excerpt_can_answer': '1. How does the Breville BES870XL Espresso Machine contribute to the third wave specialty coffee experience at home?\\n2. What specific features of the Breville Barista Express make it stand out as an all-in-one espresso machine with an integrated grinder?\\n3. What accessories are included with the Breville BES870XL Espresso Machine, and how do they enhance the overall coffee-making experience for users?', 'section_summary': 'The section discusses the Breville BES870XL Espresso Machine, highlighting its features such as dose control grinding, optimal water pressure, precise espresso extraction, and manual microfoam milk texturing for creating latte art. It also mentions the included accessories, capacity, settings, and warranty of the machine. The section emphasizes how the Breville Barista Express contributes to the third wave specialty coffee experience at home with its all-in-one design and integrated grinder.', 'text_content': \"[Excerpt from document]\\nexcerpt_keywords: Breville, Espresso Machine, Specialty Coffee, Grinder, Latte Art\\nquestions_this_excerpt_can_answer: 1. How does the Breville BES870XL Espresso Machine contribute to the third wave specialty coffee experience at home?\\n2. What specific features of the Breville Barista Express make it stand out as an all-in-one espresso machine with an integrated grinder?\\n3. What accessories are included with the Breville BES870XL Espresso Machine, and how do they enhance the overall coffee-making experience for users?\\nsection_summary: The section discusses the Breville BES870XL Espresso Machine, highlighting its features such as dose control grinding, optimal water pressure, precise espresso extraction, and manual microfoam milk texturing for creating latte art. It also mentions the included accessories, capacity, settings, and warranty of the machine. The section emphasizes how the Breville Barista Express contributes to the third wave specialty coffee experience at home with its all-in-one design and integrated grinder.\\nExcerpt:\\n-----\\n94-844: Generative AI Labs \\n \\nProduct Information \\n \\n1. Category: Home and Kitchen \\n \\nWe chose this category because it is the most popular, as well as the highest \\ncontributing category on Amazon. \\n \\nProduct: Breville BES870XL Espresso Machine, One Size, Brushed Stainless Steel \\n \\nDescription: \\nAbout this item \\nThe Breville Barista Express delivers third wave specialty coGee at home using the 4 \\nkeys formula and is part of the Barista Series that oGers all in one espresso \\nmachines with integrated grinder to go from beans to espresso in under one minute \\nDOSE CONTROL GRINDING: Integrated precision conical burr grinder grinds on \\ndemand to deliver the right amount of freshly ground coGee directly into the \\nportalter for your preferred taste with any roast of bean \\nOPTIMAL WATER PRESSURE: Low pressure pre-infusion gradually increases \\npressure at the start and helps ensure all the avors are drawn out evenly during the \\nextraction for a balanced tasting cup \\nPRECISE ESPRESSO EXTRACTION: Digital temperature control (PID) delivers water \\nat precisely the right temperature, ensuring optimal espresso extraction \\nMANUAL MICROFOAM MILK TEXTURING: The powerful steam wand performance \\nallows you to hand texture microfoam milk that enhances avor and enables \\ncreation of latte art \\nESPRESSO MACHINE WITH GRIND SIZE DIAL: Simple and intuitive, giving you \\ncontrol over the grind size no matter what type of bean you're grinding \\nESPRESSO MAKER WITH BUILT-IN COFFEE GRINDER: Innovative grinding cradle \\nallows any at home barista to grind directly into the espresso portalter for the \\nperfect espresso \\nINCLUDED ACCESSORIES: Razor Dose Trimming Tool, 54mm Stainless Steel \\nPortalter, 1 & 2 cup Single & Dual Wall Filter Baskets, CoGee Scoop, Integrated \\nTamper, Stainless Steel Milk Jug, Cleaning Disc, Tablets, Brush Tool & Allen Key, \\nWater Filter & Filter Holder \\nCAPACITY & SETTINGS: 1/2 lb Bean Hopper; 67 oz Water Tank; Single or double \\nshots; Adjustable Grind Amount and Manual Override \\nWARRANTY: 1 Year Limited Product Warranty; Power: 1600 Watts; Voltage: 120 Volts \\n \\nReviews: \\n \\n5.0 out of 5 stars great product, one of the best purchases if you drink coGee \\nReviewed in the United States on May 22, 2016\\n-----\"}\n"
     ]
    }
   ],
   "source": [
    "print(nodes[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 7cda20c2-729a-4de4-9e49-b840a41b0eff\n",
      "Text: 94-844: Generative AI Labs    Product Information    1.\n",
      "Category: Home and Kitchen    We chose this category because it is the\n",
      "most popular, as well as the highest  contributing category on Amazon.\n",
      "Product: Breville BES870XL Espresso Machine, One Size, Brushed\n",
      "Stainless Steel    Description:  About this item  The Breville Barista\n",
      "Express deli...\n"
     ]
    }
   ],
   "source": [
    "print(nodes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Retrieve Content from the Vector Store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Prompt & Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coffee Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer:\n",
      "Apologies for the confusion, but the provided information does not include any specific details on the Breville espresso machines. Please provide information about the look, feature, and possible failure of Breville espresso machines.\n"
     ]
    }
   ],
   "source": [
    "query1 = \"Find information specifically about Breville espresso machiness only.\"\n",
    "\n",
    "query_response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=[query1]\n",
    ")\n",
    "\n",
    "query_embedding = query_response.data[0].embedding\n",
    "\n",
    "res2 = pc_index.query(\n",
    "    vector=query_embedding, \n",
    "    top_k=5, \n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "retrieved_texts = []\n",
    "for match in res2['matches']:\n",
    "    actual_text = match['metadata'].get('text_content', 'No text available')\n",
    "    retrieved_texts.append(actual_text)\n",
    "\n",
    "combined_context = \"\\n\\n\".join(retrieved_texts)\n",
    "\n",
    "def rag_openai_gpt(model, query, retrieved_context):\n",
    "    \"\"\"\n",
    "    Reason over the retrieved context using OpenAI's GPT model.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Use the provided information to answer the user's question.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"The question is: {query}\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"The retrieved information is:\\n\\n{retrieved_context}\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the answer?\"}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error during OpenAI API call: {e}\")\n",
    "        return \"Error: Unable to generate an answer.\"\n",
    "\n",
    "query_to_answer = \"Provide me a more wholistic understanding (description of its look, feature, and possible failure) of Breville espresso machiness\"\n",
    "model_to_use = \"gpt-4\"\n",
    "final_answer = rag_openai_gpt(model_to_use, query_to_answer, combined_context)\n",
    "\n",
    "print(\"Final Answer:\")\n",
    "print(final_answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta Quest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer:\n",
      "I'm sorry, but I can't provide the information you're looking for because Meta Quest 3 hasn't been released yet. All details about its look, features, and possible failures remain unannounced to the public. The current latest VR headset from Meta (previously Facebook) is Meta Quest 2. Let's keep an eye out for updates from the official Meta platforms for the accurate information.\n"
     ]
    }
   ],
   "source": [
    "query1 = \"Find information specifically about Meta Quest only.\"\n",
    "\n",
    "query_response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=[query1]\n",
    ")\n",
    "\n",
    "query_embedding = query_response.data[0].embedding\n",
    "\n",
    "res2 = pc_index.query(\n",
    "    vector=query_embedding, \n",
    "    top_k=5, \n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "retrieved_texts = []\n",
    "for match in res2['matches']:\n",
    "    actual_text = match['metadata'].get('text_content', 'No text available')\n",
    "    retrieved_texts.append(actual_text)\n",
    "\n",
    "combined_context = \"\\n\\n\".join(retrieved_texts)\n",
    "\n",
    "def rag_openai_gpt(model, query, retrieved_context):\n",
    "    \"\"\"\n",
    "    Reason over the retrieved context using OpenAI's GPT model.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Use the provided information to answer the user's question.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"The question is: {query}\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"The retrieved information is:\\n\\n{retrieved_context}\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the answer?\"}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error during OpenAI API call: {e}\")\n",
    "        return \"Error: Unable to generate an answer.\"\n",
    "\n",
    "query_to_answer = \"Provide me a more wholistic understanding (description of its look, feature, and possible failure) of Meta Quest 3\"\n",
    "model_to_use = \"gpt-4\"  \n",
    "final_answer = rag_openai_gpt(model_to_use, query_to_answer, combined_context)\n",
    "\n",
    "print(\"Final Answer:\")\n",
    "print(final_answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handpan Drum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer:\n",
      "A Handpan Drum is a captivating instrument known for its ethereal, resonant sound and unique design. Resembling a UFO, its structure is typically created from two dome-shaped pieces of steel glued together with a circular, hollow interior. The rounded top - called the 'ding' - features several dents or impressions, each of which represents a different musical note. The other side, or 'gu', contains a hollow opening that affects the instrument's reverberations.\n",
      "\n",
      "The features of this instrument include its portability due to its relatively small size and light weight, often measuring between 20-24 inches in diameter at most. It also emits a rich, warm and sound that's a combination of rhythm, melody and harmony all in one instrument.\n",
      "\n",
      "In terms of possible failures, like any musical instrument, the Handpan Drum requires careful maintenance to prevent issues. Overplaying can lead to note detuning. As such, regular tunings by a professional may be necessary. Also, due to its steel construction, it's susceptible to rust and oxidation if not properly cared for. Handling it with clean, dry hands and storing it in its case when not in use can go a long way towards preserving its overall longevity and sound quality.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query1 = \"Find information specifically about Handpan Drum only.\"\n",
    "\n",
    "query_response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=[query1]\n",
    ")\n",
    "\n",
    "query_embedding = query_response.data[0].embedding\n",
    "\n",
    "res2 = pc_index.query(\n",
    "    vector=query_embedding, \n",
    "    top_k=10, \n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "retrieved_texts = []\n",
    "for match in res2['matches']:\n",
    "    actual_text = match['metadata'].get('text_content', 'No text available')\n",
    "    retrieved_texts.append(actual_text)\n",
    "\n",
    "combined_context = \"\\n\\n\".join(retrieved_texts)\n",
    "\n",
    "def rag_openai_gpt(model, query, retrieved_context):\n",
    "    \"\"\"\n",
    "    Reason over the retrieved context using OpenAI's GPT model.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Use the provided information to answer the user's question.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"The question is: {query}\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"The retrieved information is:\\n\\n{retrieved_context}\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the answer?\"}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error during OpenAI API call: {e}\")\n",
    "        return \"Error: Unable to generate an answer.\"\n",
    "\n",
    "query_to_answer = \"Provide me a more wholistic understanding (description of its look, feature, and possible failure) of Handpan Drum\"\n",
    "model_to_use = \"gpt-4\"\n",
    "final_answer = rag_openai_gpt(model_to_use, query_to_answer, combined_context)\n",
    "\n",
    "print(\"Final Answer:\")\n",
    "print(final_answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Information & Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coffee Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer:\n",
      "Key visual details about Breville espresso machines that aid in generating the product image include:\n",
      "\n",
      "- The Breville espresso machines are well-designed products with thoughtful details and sturdy construction, visually appealing materials, and a compact size that can fit into any kitchen environment.\n",
      "- The products have high-quality attached features like a magnetized hole for tamper storage, a hidden accessories tray in the base of the machine, and an area on the machine's top surface that stays warm from the boiler to keep your portafilter and coffee cup warm.\n",
      "- Breville Barista Express offers all-in-one espresso machines with an integrated grinder that goes from beans to espresso in under one minute. \n",
      "- The machines have a conical burr grinder, a simple and intuitive grind size dial, and a direct grind-to-portafilter option.\n",
      "- The Breville espresso machines come with manual microfoam milk texturing that enhance flavor and enables creation of latte art.\n",
      "- The products come with a variety of included accessories such as a Razor Dose Trimming Tool, Stainless Steel Portafilter, Single & Dual Wall Filter Baskets, Coffee Scoop, Integrated Tamper, Stainless Steel Milk Jug, among others.\n",
      "- The machines are versatile with adjustable grind amount settings, and single or double shot options.\n",
      "- Despite the high-end features, these machines are user-friendly and suitable for home use, including those who aren't professional baristas.\n",
      "- The machines are designed to provide espresso consistently and only change as your beans age. The water boiler heats up very quickly and is ready to make a shot less than 2 minutes after hitting the power button.\n",
      "  \n",
      "These details together help generate a comprehensive visual presentation of Breville's espresso machines and their capabilities.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query1 = \"Find information specifically about Breville espresso machiness only.\"\n",
    "\n",
    "query_response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=[query1]\n",
    ")\n",
    "\n",
    "query_embedding = query_response.data[0].embedding\n",
    "\n",
    "res2 = pc_index.query(\n",
    "    vector=query_embedding, \n",
    "    top_k=5, \n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "retrieved_texts = []\n",
    "for match in res2['matches']:\n",
    "    actual_text = match['metadata'].get('text_content', 'No text available')\n",
    "    retrieved_texts.append(actual_text)\n",
    "\n",
    "combined_context = \"\\n\\n\".join(retrieved_texts)\n",
    "\n",
    "def rag_openai_gpt(model, query, retrieved_context):\n",
    "    \"\"\"\n",
    "    Reason over the retrieved context using OpenAI's GPT model.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Use the provided information to answer the user's question.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"The question is: {query}\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"The retrieved information is:\\n\\n{retrieved_context}\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the answer?\"}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error during OpenAI API call: {e}\")\n",
    "        return \"Error: Unable to generate an answer.\"\n",
    "\n",
    "query_to_answer = \"Provide me some bullet points of visual informations of Breville espresso machiness that helps generating product image\"\n",
    "model_to_use = \"gpt-4\"\n",
    "final_answer = rag_openai_gpt(model_to_use, query_to_answer, combined_context)\n",
    "\n",
    "print(\"Final Answer:\")\n",
    "print(final_answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta Quest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer:\n",
      "Visual Information on the Meta Quest 3 VR headset includes:\n",
      "\n",
      "- Offers immersive mixed reality experiences.\n",
      "- Comes with a 4K + Infinite Display feature contributing to a lifelike gaming experience.\n",
      "- Comes preloaded with exclusive content like Batman: Arkham Shadow.\n",
      "- Offers more storage for apps and games.\n",
      "- Device creates a wider, taller, expansive field of view for the gamers.\n",
      "- Resolution per eye is recorded to be 2064x2208.\n",
      "- Has an improved room scanning tool for a smooth gaming experience.\n",
      "- Can perform exceptionally well with a gaming PC.\n",
      "- Comes with an option to stream games.\n",
      "- Battery life varies depending on the use. However, using Augmented Reality can cut the battery life into half.\n",
      "- Possible issues with the Quest Link software, causing difficulty in connecting the headset to PC.\n",
      "- The default strap is considered uncomfortable by some users. Opting for a third-party strap could be more beneficial.\n",
      "- Visual clarity is high compared to other VR headsets like PS4 VR.\n",
      "- Sound quality is reportedly good and the device can be used without additional headsets for sound.\n",
      "- Downloadable games offered are between 5-40 GB therefore larger storage options are recommended.\n"
     ]
    }
   ],
   "source": [
    "query1 = \"Find information specifically about Meta Quest only.\"\n",
    "\n",
    "query_response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=[query1]\n",
    ")\n",
    "\n",
    "query_embedding = query_response.data[0].embedding\n",
    "\n",
    "res2 = pc_index.query(\n",
    "    vector=query_embedding, \n",
    "    top_k=5, \n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "retrieved_texts = []\n",
    "for match in res2['matches']:\n",
    "    actual_text = match['metadata'].get('text_content', 'No text available')\n",
    "    retrieved_texts.append(actual_text)\n",
    "\n",
    "combined_context = \"\\n\\n\".join(retrieved_texts)\n",
    "\n",
    "def rag_openai_gpt(model, query, retrieved_context):\n",
    "    \"\"\"\n",
    "    Reason over the retrieved context using OpenAI's GPT model.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Use the provided information to answer the user's question.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"The question is: {query}\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"The retrieved information is:\\n\\n{retrieved_context}\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the answer?\"}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error during OpenAI API call: {e}\")\n",
    "        return \"Error: Unable to generate an answer.\"\n",
    "\n",
    "query_to_answer = \"Provide me some bullet points of visual information of Meta Quest 3 that helps generating product image\"\n",
    "model_to_use = \"gpt-4\"\n",
    "final_answer = rag_openai_gpt(model_to_use, query_to_answer, combined_context)\n",
    "\n",
    "print(\"Final Answer:\")\n",
    "print(final_answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handpan Drum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer:\n",
      "- The Handpan Drum is crafted from premium 1.2mm thick steel using advanced high-temperature heat treatment techniques for durability, robustness, and resistance to rust.\n",
      "- Each drum undergoes expert manual tuning to ensure precise tones and harmonies, resulting in unmatched accuracy and resonance.\n",
      "- The sound quality of the Handpan Drum is described as clean, ethereal, and captivating, purifying the listener's soul and making it suitable for music education, yoga meditation, and musical performances.\n",
      "- The Handpan Drum is easy to play and includes 10 notes in D minor (A3, Bb3, C4, D3, D4, E4, F4, G4, A4, C5). No other equipment is necessary.\n",
      "- Some HandPans may have differences in tuning, with some being closer to A = 440 Hz rather than the advertised A = 432 Hz.\n",
      "- Depending on the model, the Handpan Drum may come in different colors like black or gold. Sizes can range from 14 inches to 22 inches.\n",
      "- Each Handpan Drum purchase comes with a complete package including a carrying case, drum stand, two drumsticks, and a cleaning cloth.\n",
      "- The manufacturer offers a 6-month warranty and round-the-clock customer service. \n",
      "- According to customer reviews, the Handpan Drum is great for beginners, brings joy to a musical home, possesses clear and beautiful tones, is of good quality and it is particularly popular for group jam sessions.\n"
     ]
    }
   ],
   "source": [
    "query1 = \"Find information specifically about Handpan Drum only.\"\n",
    "\n",
    "query_response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=[query1]\n",
    ")\n",
    "\n",
    "query_embedding = query_response.data[0].embedding\n",
    "\n",
    "res2 = pc_index.query(\n",
    "    vector=query_embedding, \n",
    "    top_k=5, \n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "retrieved_texts = []\n",
    "for match in res2['matches']:\n",
    "    actual_text = match['metadata'].get('text_content', 'No text available')\n",
    "    retrieved_texts.append(actual_text)\n",
    "\n",
    "combined_context = \"\\n\\n\".join(retrieved_texts)\n",
    "\n",
    "def rag_openai_gpt(model, query, retrieved_context):\n",
    "    \"\"\"\n",
    "    Reason over the retrieved context using OpenAI's GPT model.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Use the provided information to answer the user's question.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"The question is: {query}\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"The retrieved information is:\\n\\n{retrieved_context}\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the answer?\"}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error during OpenAI API call: {e}\")\n",
    "        return \"Error: Unable to generate an answer.\"\n",
    "\n",
    "query_to_answer = \"Provide me some bullet points of visual information of Handpan Drum that helps generating product image\"\n",
    "model_to_use = \"gpt-4\"\n",
    "final_answer = rag_openai_gpt(model_to_use, query_to_answer, combined_context)\n",
    "\n",
    "print(\"Final Answer:\")\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Json File Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breville espresso machiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer:\n",
      "{\n",
      "  \"Product_Details\": {\n",
      "    \"Product\": \"Breville BES870XL Espresso Machine\",\n",
      "    \"Size\": \"One Size\",\n",
      "    \"Colors\": \"Brushed Stainless Steel\",\n",
      "    \"Material\": \"Stainless Steel\",\n",
      "    \"Notable_Features\":\n",
      "    [\n",
      "      \"High-quality design\",\n",
      "      \"Consistent espresso production\",\n",
      "      \"Quick water boiler heating\",\n",
      "      \"High-quality milk foam production\",\n",
      "      \"In-built conical burr grinder\",\n",
      "      \"Precision dose control grinding\",\n",
      "      \"Optimal water pressure control\",\n",
      "      \"Precise espresso extraction with digital temperature control\",\n",
      "      \"Manual micro foam milk texturing\",\n",
      "      \"User-friendly control and movable parts\",\n",
      "      \"Integrated tamper\",\n",
      "      \"Mass: 1/2 lb Bean Hopper; 67 oz Water Tank\",\n",
      "      \"Settings: Single or double shots; Adjustable Grind Amount and Manual Override\",\n",
      "      \"Power and Voltage: 1600 Watts; 120 Volts\",\n",
      "      \"Useful for home baristas and beginners\"\n",
      "    ],\n",
      "    \"Accessories_Included\":\n",
      "    [\n",
      "      \"Razor Dose Trimming Tool\",\n",
      "      \"54mm Stainless Steel Portalter\",\n",
      "      \"1 & 2 cup Single & Dual Wall Filter Baskets\",\n",
      "      \"Coffee Scoop\",\n",
      "      \"Stainless Steel Milk Jug\",\n",
      "      \"Cleaning Disc, Tablets, Brush Tool & Allen Key\",\n",
      "      \"Water Filter & Filter Holder\"\n",
      "    ],\n",
      "    \"Customer_Service\":\n",
      "    [\n",
      "      \"Usually good about fixing or replacing the machines and parts\",\n",
      "      \"Provides assistance and repairs even after the warranty period\"\n",
      "    ],\n",
      "    \"Product_Ratings\": \"Highly rated, especially for home use and novice users\",\n",
      "    \"Maintenance_Tools\": \"Cleaning tablets, descaler, and replacement filters\",\n",
      "    \"Customer_Experiences\": \"Extracts high-quality espresso and is easy to use\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query1 = \"Find information specifically about visual information of Breville espresso machiness only.\"\n",
    "\n",
    "query_response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=[query1]\n",
    ")\n",
    "\n",
    "query_embedding = query_response.data[0].embedding\n",
    "\n",
    "res2 = pc_index.query(\n",
    "    vector=query_embedding, \n",
    "    top_k=5, \n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "retrieved_texts = []\n",
    "for match in res2['matches']:\n",
    "    actual_text = match['metadata'].get('text_content', 'No text available')\n",
    "    retrieved_texts.append(actual_text)\n",
    "\n",
    "combined_context = \"\\n\\n\".join(retrieved_texts)\n",
    "\n",
    "def rag_openai_gpt(model, query, retrieved_context):\n",
    "    \"\"\"\n",
    "    Reason over the retrieved context using OpenAI's GPT model.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Use the provided information to answer the user's question.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"The question is: {query}\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"The retrieved information is:\\n\\n{retrieved_context}\"},\n",
    "        {\"role\": \"user\", \"content\": \"Using the information provided, generate a structured JSON file containing details of the product\"}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error during OpenAI API call: {e}\")\n",
    "        return \"Error: Unable to generate an answer.\"\n",
    "\n",
    "query_to_answer = \"Provide me bullet point info of Breville espresso machines that could help design its product image. The JSON should include attributes like size, colors, material, notable features, etc. Ensure the response is strictly in JSON format without any explanations.\"\n",
    "model_to_use = \"gpt-4\"  \n",
    "final_answer = rag_openai_gpt(model_to_use, query_to_answer, combined_context)\n",
    "\n",
    "print(\"Final Answer:\")\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer:\n",
      "{\n",
      "  \"Product_Name\": \"Meta Quest 3 512GB\",\n",
      "  \"Product_Details\": {\n",
      "    \"Size\": \"512 GB\",\n",
      "    \"Style\": \"Headset + Controllers\",\n",
      "    \"Resolution\": \"4K + Infinite Display (2064x2208 resolution per eye)\",\n",
      "    \"Sound\": \"Rich spatial audio\",\n",
      "    \"Material\": \"Not specified\",\n",
      "    \"Colors\": \"Not specified\",\n",
      "    \"Features\": {\n",
      "      \"Mixed Reality Capability\": \"Ability to blend digital objects into physical space\",\n",
      "      \"4K + Infinite Display\": \"Offers wide, tall, expansive field of view\",\n",
      "      \"Premium Gaming Experience\": \"Improved resolution, crisper visuals, reduced screen door effect compared to predecessor models\",\n",
      "      \"Room Scanning Tool\": \"Improved tool for virtual room creation using multiple cameras\",\n",
      "      \"Battery\": \"Faster consumption especially in augmented reality mode, battery pack or charging cable recommended for prolonged use\",\n",
      "      \"Extra Content\": \"Inclusive of Batman: Arkham Shadow and a 3-month trial of Meta Quest+\",\n",
      "      \"Wireless Capability\": \"High performance standalone mode, as well as streaming from a gaming PC via Meta's Air Link\",\n",
      "      \"Comfort Features\": \"A connected nose ridge can adjust for individual user comfort\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query1 = \"Find information specifically about visual information of Meta Quest only.\"\n",
    "\n",
    "query_response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=[query1]\n",
    ")\n",
    "\n",
    "query_embedding = query_response.data[0].embedding\n",
    "\n",
    "res2 = pc_index.query(\n",
    "    vector=query_embedding, \n",
    "    top_k=5, \n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "retrieved_texts = []\n",
    "for match in res2['matches']:\n",
    "    actual_text = match['metadata'].get('text_content', 'No text available')\n",
    "    retrieved_texts.append(actual_text)\n",
    "\n",
    "combined_context = \"\\n\\n\".join(retrieved_texts)\n",
    "\n",
    "def rag_openai_gpt(model, query, retrieved_context):\n",
    "    \"\"\"\n",
    "    Reason over the retrieved context using OpenAI's GPT model.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Use the provided information to answer the user's question.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"The question is: {query}\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"The retrieved information is:\\n\\n{retrieved_context}\"},\n",
    "        {\"role\": \"user\", \"content\": \"Using the information provided, generate a structured JSON file containing details of the product\"}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error during OpenAI API call: {e}\")\n",
    "        return \"Error: Unable to generate an answer.\"\n",
    "\n",
    "query_to_answer = \"Provide me bullet point info of Meta Quest 3 that could help design its product image. The JSON should include attributes like size, colors, material, notable features, etc. Ensure the response is strictly in JSON format without any explanations.\"\n",
    "model_to_use = \"gpt-4\"  \n",
    "final_answer = rag_openai_gpt(model_to_use, query_to_answer, combined_context)\n",
    "\n",
    "print(\"Final Answer:\")\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer:\n",
      "{\n",
      "  \"Handpan Drum\": {\n",
      "    \"Size\": [\n",
      "      \"22 Inches\",\n",
      "      \"14 Inches\"\n",
      "    ],\n",
      "    \"Color\": [\n",
      "      \"Gold\",\n",
      "      \"Black\",\n",
      "      \"Purple\",\n",
      "      \"Print Black 10 Sounds\"\n",
      "    ],\n",
      "    \"Material\": \"Premium Steel\",\n",
      "    \"Notable Features\": {\n",
      "      \"Tuning\": \"D Minor Kurd, 432Hz, 10 Notes\",\n",
      "      \"Ease of Use\": \"Easy to pick up without any other equipment\",\n",
      "      \"Includes Accessories\": \"Velvet bag, two 'drum sticks', small booklet of songs\",\n",
      "      \"Natural Woven Decoration\": \"Yes\",\n",
      "      \"Sound Quality\": \"Sound is clear with the exception of bass notes, which can sound flat\",\n",
      "      \"Packed Well\": \"Yes\"\n",
      "    },\n",
      "    \"Customer Reviews\": [\n",
      "      {\n",
      "        \"Rating\": \"5.0 out of 5 stars\",\n",
      "        \"Review Date\": \"October 23, 2024\",\n",
      "        \"Review Text\": \"Excellent, definitely would upgrade soon\"\n",
      "      },\n",
      "      {\n",
      "        \"Rating\": \"4.0 out of 5 stars\",\n",
      "        \"Review Date\": \"July 6, 2024\",\n",
      "        \"Review Text\": \"Good instrument, tuning is not A = 432 Hz.\"\n",
      "      },\n",
      "      {\n",
      "        \"Rating\": \"4.0 out of 5 stars\",\n",
      "        \"Review Date\": \"July 5, 2024\",\n",
      "        \"Review Text\": \"Sound clarity inconsistent but satisfies, bass notes can sound flat\"\n",
      "      },\n",
      "      {\n",
      "        \"Rating\": \"5.0 out of 5 stars\",\n",
      "        \"Review Date\": \"October 16, 2024\",\n",
      "        \"Review Text\": \"Great quality\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query1 = \"Find information specifically about visual information of Handpan Drum only.\"\n",
    "\n",
    "query_response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=[query1]\n",
    ")\n",
    "\n",
    "query_embedding = query_response.data[0].embedding\n",
    "\n",
    "res2 = pc_index.query(\n",
    "    vector=query_embedding, \n",
    "    top_k=5, \n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "retrieved_texts = []\n",
    "for match in res2['matches']:\n",
    "    actual_text = match['metadata'].get('text_content', 'No text available')\n",
    "    retrieved_texts.append(actual_text)\n",
    "\n",
    "combined_context = \"\\n\\n\".join(retrieved_texts)\n",
    "\n",
    "def rag_openai_gpt(model, query, retrieved_context):\n",
    "    \"\"\"\n",
    "    Reason over the retrieved context using OpenAI's GPT model.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Use the provided information to answer the user's question.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"The question is: {query}\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"The retrieved information is:\\n\\n{retrieved_context}\"},\n",
    "        {\"role\": \"user\", \"content\": \"Using the information provided, generate a structured JSON file containing details of the product\"}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error during OpenAI API call: {e}\")\n",
    "        return \"Error: Unable to generate an answer.\"\n",
    "\n",
    "query_to_answer = \"Provide me bullet point info of Handpan Drum that could help design its product image. The JSON should include attributes like size, colors, material, notable features, etc. Ensure the response is strictly in JSON format without any explanations.\"\n",
    "model_to_use = \"gpt-4\"  \n",
    "final_answer = rag_openai_gpt(model_to_use, query_to_answer, combined_context)\n",
    "\n",
    "print(\"Final Answer:\")\n",
    "print(final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
